#!/usr/bin/env python3
"""
æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿ
åŸºäºå…³é”®è¯å’Œå†…å®¹åˆ†æè¿›è¡Œå¤šç»´åº¦åˆ†ç±»
"""

import re
from typing import Dict, List, Set, Tuple
from dataclasses import dataclass

@dataclass
class ClassificationResult:
    """åˆ†ç±»ç»“æœ"""
    primary_category: str
    secondary_categories: List[str]
    tech_stack: List[str]
    importance_score: float
    trending_score: float
    keywords: List[str]

class IntelligentClassifier:
    """æ™ºèƒ½åˆ†ç±»å™¨"""
    
    def __init__(self):
        self.category_keywords = self._load_category_keywords()
        self.tech_stack_keywords = self._load_tech_stack_keywords()
        self.importance_keywords = self._load_importance_keywords()
        self.trending_keywords = self._load_trending_keywords()
    
    def classify_article(self, title: str, content: str, source_category: str) -> ClassificationResult:
        """åˆ†ç±»æ–‡ç« """
        
        # åˆå¹¶æ ‡é¢˜å’Œå†…å®¹è¿›è¡Œåˆ†æ
        full_text = f"{title} {content}".lower()
        
        # æå–å…³é”®è¯
        keywords = self._extract_keywords(full_text)
        
        # ä¸»åˆ†ç±»ï¼ˆåŸºäºä¿¡æ¯æºå’Œå†…å®¹ï¼‰
        primary_category = self._determine_primary_category(full_text, source_category)
        
        # æ¬¡åˆ†ç±»
        secondary_categories = self._determine_secondary_categories(full_text)
        
        # æŠ€æœ¯æ ˆè¯†åˆ«
        tech_stack = self._identify_tech_stack(full_text)
        
        # é‡è¦æ€§è¯„åˆ†
        importance_score = self._calculate_importance_score(full_text, keywords)
        
        # è¶‹åŠ¿æ€§è¯„åˆ†
        trending_score = self._calculate_trending_score(full_text, keywords)
        
        return ClassificationResult(
            primary_category=primary_category,
            secondary_categories=secondary_categories,
            tech_stack=tech_stack,
            importance_score=importance_score,
            trending_score=trending_score,
            keywords=keywords
        )
    
    def _load_category_keywords(self) -> Dict[str, List[str]]:
        """åŠ è½½åˆ†ç±»å…³é”®è¯"""
        return {
            'ai_ml': [
                'artificial intelligence', 'machine learning', 'deep learning', 'neural network',
                'gpt', 'llm', 'transformer', 'chatgpt', 'claude', 'gemini', 'openai',
                'anthropic', 'deepmind', 'hugging face', 'pytorch', 'tensorflow',
                'computer vision', 'nlp', 'natural language processing', 'generative ai'
            ],
            'github_dev': [
                'github', 'git', 'repository', 'open source', 'pull request', 'commit',
                'copilot', 'actions', 'codespace', 'developer', 'programming', 'code',
                'software development', 'version control', 'collaboration'
            ],
            'startup_funding': [
                'startup', 'funding', 'investment', 'venture capital', 'vc', 'series a',
                'series b', 'ipo', 'acquisition', 'merger', 'valuation', 'unicorn',
                'y combinator', 'accelerator', 'incubator', 'entrepreneur'
            ],
            'product_launch': [
                'launch', 'release', 'announcement', 'new product', 'feature',
                'update', 'beta', 'preview', 'coming soon', 'available now'
            ],
            'tech_trends': [
                'trend', 'future', 'innovation', 'breakthrough', 'revolution',
                'disruption', 'emerging', 'next generation', 'cutting edge'
            ],
            'security': [
                'security', 'privacy', 'cybersecurity', 'hack', 'breach', 'vulnerability',
                'encryption', 'authentication', 'malware', 'phishing'
            ],
            'cloud_infra': [
                'cloud', 'aws', 'azure', 'gcp', 'kubernetes', 'docker', 'serverless',
                'microservices', 'infrastructure', 'devops', 'ci/cd'
            ]
        }
    
    def _load_tech_stack_keywords(self) -> Dict[str, List[str]]:
        """åŠ è½½æŠ€æœ¯æ ˆå…³é”®è¯"""
        return {
            'languages': [
                'python', 'javascript', 'typescript', 'java', 'go', 'rust', 'c++',
                'swift', 'kotlin', 'php', 'ruby', 'scala', 'r', 'julia'
            ],
            'frameworks': [
                'react', 'vue', 'angular', 'django', 'flask', 'fastapi', 'express',
                'spring', 'rails', 'laravel', 'nextjs', 'nuxt', 'svelte'
            ],
            'databases': [
                'postgresql', 'mysql', 'mongodb', 'redis', 'elasticsearch',
                'cassandra', 'dynamodb', 'sqlite', 'neo4j'
            ],
            'cloud_platforms': [
                'aws', 'azure', 'gcp', 'vercel', 'netlify', 'heroku', 'digitalocean'
            ],
            'ai_tools': [
                'pytorch', 'tensorflow', 'keras', 'scikit-learn', 'pandas',
                'numpy', 'jupyter', 'hugging face', 'langchain', 'llamaindex'
            ]
        }
    
    def _load_importance_keywords(self) -> List[str]:
        """åŠ è½½é‡è¦æ€§å…³é”®è¯"""
        return [
            'breakthrough', 'revolutionary', 'game-changing', 'major', 'significant',
            'important', 'critical', 'milestone', 'historic', 'unprecedented',
            'billion', 'million', 'record', 'largest', 'first', 'new'
        ]
    
    def _load_trending_keywords(self) -> List[str]:
        """åŠ è½½è¶‹åŠ¿æ€§å…³é”®è¯"""
        return [
            'trending', 'viral', 'popular', 'hot', 'rising', 'growing',
            'emerging', 'latest', 'new', 'fresh', 'recent', 'today',
            'this week', 'breaking', 'just announced', 'now available'
        ]
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå¯ä»¥åç»­ä¼˜åŒ–ä¸ºæ›´å¤æ‚çš„NLPæ–¹æ³•ï¼‰
        words = re.findall(r'\b[a-zA-Z]{3,}\b', text.lower())
        
        # è¿‡æ»¤å¸¸è§åœç”¨è¯
        stop_words = {
            'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'had',
            'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his',
            'how', 'its', 'may', 'new', 'now', 'old', 'see', 'two', 'who', 'boy',
            'did', 'man', 'men', 'put', 'say', 'she', 'too', 'use', 'way', 'will'
        }
        
        keywords = [word for word in words if word not in stop_words and len(word) > 3]
        
        # è¿”å›é¢‘ç‡æœ€é«˜çš„å…³é”®è¯
        from collections import Counter
        word_counts = Counter(keywords)
        return [word for word, count in word_counts.most_common(10)]
    
    def _determine_primary_category(self, text: str, source_category: str) -> str:
        """ç¡®å®šä¸»åˆ†ç±»"""
        
        # åŸºäºä¿¡æ¯æºçš„åˆå§‹åˆ†ç±»
        category_mapping = {
            'github': 'github_dev',
            'ai': 'ai_ml',
            'startup': 'startup_funding',
            'silicon_valley': 'tech_trends',
            'tech': 'product_launch'
        }
        
        base_category = category_mapping.get(source_category, 'tech_trends')
        
        # åŸºäºå†…å®¹çš„åˆ†ç±»è°ƒæ•´
        max_score = 0
        best_category = base_category
        
        for category, keywords in self.category_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > max_score:
                max_score = score
                best_category = category
        
        return best_category
    
    def _determine_secondary_categories(self, text: str) -> List[str]:
        """ç¡®å®šæ¬¡åˆ†ç±»"""
        secondary = []
        
        for category, keywords in self.category_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score >= 2:  # è‡³å°‘åŒ¹é…2ä¸ªå…³é”®è¯
                secondary.append(category)
        
        return secondary[:3]  # æœ€å¤š3ä¸ªæ¬¡åˆ†ç±»
    
    def _identify_tech_stack(self, text: str) -> List[str]:
        """è¯†åˆ«æŠ€æœ¯æ ˆ"""
        tech_stack = []
        
        for stack_type, technologies in self.tech_stack_keywords.items():
            for tech in technologies:
                if tech in text:
                    tech_stack.append(tech)
        
        return list(set(tech_stack))[:5]  # å»é‡ï¼Œæœ€å¤š5ä¸ª
    
    def _calculate_importance_score(self, text: str, keywords: List[str]) -> float:
        """è®¡ç®—é‡è¦æ€§è¯„åˆ† (0-1)"""
        score = 0.0
        
        # åŸºäºé‡è¦æ€§å…³é”®è¯
        importance_matches = sum(1 for keyword in self.importance_keywords if keyword in text)
        score += importance_matches * 0.1
        
        # åŸºäºæ•°å­—ï¼ˆé‡‘é¢ã€ç”¨æˆ·æ•°ç­‰ï¼‰
        numbers = re.findall(r'\b\d+(?:\.\d+)?\s*(?:billion|million|thousand|k|m|b)\b', text.lower())
        if numbers:
            score += 0.2
        
        # åŸºäºå…¬å¸çŸ¥ååº¦
        famous_companies = [
            'google', 'microsoft', 'apple', 'amazon', 'meta', 'tesla', 'nvidia',
            'openai', 'anthropic', 'github', 'vercel', 'stripe'
        ]
        company_matches = sum(1 for company in famous_companies if company in text)
        score += company_matches * 0.1
        
        return min(score, 1.0)
    
    def _calculate_trending_score(self, text: str, keywords: List[str]) -> float:
        """è®¡ç®—è¶‹åŠ¿æ€§è¯„åˆ† (0-1)"""
        score = 0.0
        
        # åŸºäºè¶‹åŠ¿æ€§å…³é”®è¯
        trending_matches = sum(1 for keyword in self.trending_keywords if keyword in text)
        score += trending_matches * 0.15
        
        # åŸºäºæ—¶é—´ç›¸å…³è¯æ±‡
        time_words = ['today', 'yesterday', 'this week', 'recently', 'just', 'now']
        time_matches = sum(1 for word in time_words if word in text)
        score += time_matches * 0.1
        
        # åŸºäºç¤¾äº¤åª’ä½“ç›¸å…³è¯æ±‡
        social_words = ['viral', 'trending', 'popular', 'buzz', 'hype']
        social_matches = sum(1 for word in social_words if word in text)
        score += social_matches * 0.2
        
        return min(score, 1.0)
    
    def classify_news(self, news_item: Dict) -> Dict:
        """åˆ†ç±»æ–°é—»æ¡ç›®ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        title = news_item.get('title', '')
        summary = news_item.get('summary', '')
        source_category = news_item.get('category', 'tech')
        
        # ä½¿ç”¨ç°æœ‰çš„åˆ†ç±»æ–¹æ³•
        result = self.classify_article(title, summary, source_category)
        
        # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
        classified_news = news_item.copy()
        classified_news.update({
            'ä¸»åˆ†ç±»': result.primary_category,
            'æ¬¡åˆ†ç±»': result.secondary_categories,
            'æŠ€æœ¯æ ˆ': result.tech_stack,
            'é‡è¦æ€§è¯„åˆ†': result.importance_score,
            'è¶‹åŠ¿æ€§è¯„åˆ†': result.trending_score,
            'å…³é”®è¯': result.keywords,
            'ç»¼åˆè¯„åˆ†': (result.importance_score + result.trending_score) / 2
        })
        
        return classified_news

if __name__ == "__main__":
    # æµ‹è¯•åˆ†ç±»å™¨
    classifier = IntelligentClassifier()
    
    # æµ‹è¯•æ–‡ç« 
    test_articles = [
        {
            'title': 'OpenAI Releases GPT-5 with Revolutionary Capabilities',
            'content': 'OpenAI today announced GPT-5, a breakthrough in artificial intelligence that demonstrates unprecedented reasoning capabilities. The new model shows significant improvements in coding, mathematics, and creative writing.',
            'source_category': 'ai'
        },
        {
            'title': 'GitHub Copilot Gets Major Update with AI Pair Programming',
            'content': 'GitHub has released a major update to Copilot, introducing new AI-powered features for developers. The update includes better code suggestions and integration with popular IDEs.',
            'source_category': 'github'
        },
        {
            'title': 'Startup Raises $100M Series B for Revolutionary Cloud Platform',
            'content': 'A promising startup has secured $100 million in Series B funding to develop their next-generation cloud infrastructure platform. The investment was led by Andreessen Horowitz.',
            'source_category': 'startup'
        }
    ]
    
    print("ğŸ§  æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    for i, article in enumerate(test_articles, 1):
        print(f"\nğŸ“° æµ‹è¯•æ–‡ç«  {i}: {article['title']}")
        
        result = classifier.classify_article(
            article['title'],
            article['content'],
            article['source_category']
        )
        
        print(f"ğŸ¯ ä¸»åˆ†ç±»: {result.primary_category}")
        print(f"ğŸ“‹ æ¬¡åˆ†ç±»: {', '.join(result.secondary_categories) if result.secondary_categories else 'æ— '}")
        print(f"ğŸ’» æŠ€æœ¯æ ˆ: {', '.join(result.tech_stack) if result.tech_stack else 'æ— '}")
        print(f"â­ é‡è¦æ€§: {result.importance_score:.2f}")
        print(f"ğŸ”¥ è¶‹åŠ¿æ€§: {result.trending_score:.2f}")
        print(f"ğŸ”‘ å…³é”®è¯: {', '.join(result.keywords[:5])}") 